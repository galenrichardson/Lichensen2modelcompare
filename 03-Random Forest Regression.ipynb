{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24fad091",
   "metadata": {},
   "source": [
    "Citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, time, csv,math,scipy,joblib,matplotlib\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from scipy.stats import pearsonr,gaussian_kde\n",
    "#displaying data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow,figure\n",
    "plt.rcParams['figure.dpi'] = 300 \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a26dfb0",
   "metadata": {},
   "source": [
    "## Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_csv = r'D:\\Training_Data_Creation\\Pointer_files\\Train_Tiles40.csv'\n",
    "Val_csv = r'D:\\Training_Data_Creation\\Pointer_files\\Val_Tiles40.csv'\n",
    "Test_csv = r'D:\\Training_Data_Creation\\Pointer_files\\Test_Tiles40.csv'\n",
    "Testp_csv = r'D:\\Training_Data_Creation\\Pointer_files\\TestP40_Tiles50.csv'\n",
    "SEED = 71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_to_datasets(incsv):\n",
    "    dset=pd.read_csv(incsv)\n",
    "    dset_labels = dset.pop('Trueval')\n",
    "    dset= np.array(dset)/65535 #divide by 65535 since that is the max 16bit int value\n",
    "    dset_labels=np.array(dset_labels)/100 #divide by 100 since that is max mask pixel value\n",
    "    return dset,dset_labels\n",
    "#splitting the datasets into values and labels\n",
    "train,train_labels=process_csv_to_datasets(Train_csv)\n",
    "val,val_labels=process_csv_to_datasets(Val_csv)\n",
    "test,test_labels=process_csv_to_datasets(Test_csv)\n",
    "testp,testp_labels=process_csv_to_datasets(Testp_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs \n",
    "#Importing metric functions\n",
    "from .defs.Thesis_Functions import dtime,calculate_metrics,time_and_metrics\n",
    "#Importing plotting functions\n",
    "from .defs.Thesis_Functions import make_scatter_from_results,plot_hist_save,Feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0100a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(path,Results,Results_str,model,model_str):\n",
    "    '''used to save scikitlearn models'''\n",
    "    mae,r2,dt_string=time_and_metrics(Results)\n",
    "    #saves RF model\n",
    "    joblib.dump(model, r\"{}\\{}_{}-{}_{}.joblib\".format(path,model_str,Results_str,mae,r2,dt_string),compress=3)\n",
    "    print('model saved')\n",
    "def load_model(path):\n",
    "    '''used to load scikitlearn models'''\n",
    "    loaded_rf = joblib.load(path)\n",
    "    print('model loaded')\n",
    "    return loaded_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Results_RF(model):\n",
    "    '''Results is a standardize pd.dataframe used across all models. it consists of 2 columns, 0 and \"pred\". \n",
    "    All of the row references an instance of a test/validation dataset.'''\n",
    "    #copies the labels of a dataset\n",
    "    Results_val,Results_test,Results_testp=pd.DataFrame(val_labels.copy()),pd.DataFrame(test_labels.copy()),pd.DataFrame(testp_labels.copy())\n",
    "    #makes a prediction from the dataset values, creates new column\n",
    "    Results_val[\"pred\"],Results_test[\"pred\"],Results_testp[\"pred\"]= model.predict(val),model.predict(test),model.predict(testp)\n",
    "    return Results_val,Results_test,Results_testp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3ac45",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b8ab3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''USE when you are ready to fully test RF model, space in n_estimators will prevent from activating'''\n",
    "startmain = time.time()\n",
    "best_mae=10000\n",
    "n_estimators = [30,100,300,1000]\n",
    "max_features,criterion = [\"auto\",\"sqrt\", \"log2\"],\"absolute_error\"\n",
    "for estimators in n_estimators:\n",
    "    for features in max_features:\n",
    "        start=time.time()\n",
    "        rf_reg = RandomForestRegressor(n_estimators=estimators, max_features=features, criterion=criterion,n_jobs=-1)  # Using default values for everything else\n",
    "        rf_reg.fit(train, train_labels) #fitting the model\n",
    "        end=time.time()\n",
    "        newX,newy = val,val_labels\n",
    "        pred = rf_reg.predict(newX) #making predictions\n",
    "        mae = np.mean(np.abs(newy  - pred))\n",
    "        rf_val,rf_test,rf_testpt=create_Results_RF(rf_reg)\n",
    "        save_model(r'D:\\Training_Data_Creation\\01-logs\\RF_reg',rf_val,'RF_val{}{}'.format(str(estimators),features),rf_reg,'RFreg')\n",
    "        Results=rf_val\n",
    "        strResults='val{}{}'.format(str(estimators),features)\n",
    "        make_scatter_from_results(Results,strResults,'RFreg',r'D:\\Training_Data_Creation\\Results_Scatter')\n",
    "        print(\"n_estimators: \" + str(estimators) + \"; max_features: \" + features + \"; MAE: \" + str(mae))\n",
    "        print(\"Training Completed with {} estimator and {} features in {} sec\".format(estimators,features,str(\"%.2f\"%(end-start))))\n",
    "        if mae < best_mae:\n",
    "            best_mae,best_n_estimators,best_max_features = mae,estimators,features\n",
    "print(\"Based on these results we will proceed with \" + str(best_n_estimators) + \" estimators, and \" + best_max_features + \" features\")\n",
    "endmain = time.time()\n",
    "print(\"Overall runtime is \"+str(\"%.2f\"%(endmain-startmain))+' sec')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5b23a",
   "metadata": {},
   "source": [
    "## Evaluating the best model on different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1384b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_rf = joblib.load(r\"D:\\Training_Data_Creation\\01-logs\\RF_reg\\RFreg_RF_val1000sqrt-5.529_0.735.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create all the results for different datasets\n",
    "rf_val,rf_test,rf_testp=create_Results_RF(loaded_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b248cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define Results dataset and strResults for evaluating and saving\n",
    "Results=rf_val\n",
    "strResults='val'\n",
    "\n",
    "make_scatter_from_results(Results,strResults,'RFreg',r'D:\\Training_Data_Creation\\Results_Scatter')\n",
    "mae,r,p=calculate_metrics(Results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dislplaying feature importance\n",
    "Feature_importance(loaded_rf,val,val_labels,r'D:\\Training_Data_Creation\\Results_Scatter\\RFreg\\Feature_imp_Val_RF_REG.png')\n",
    "Feature_importance(loaded_rf,test,test_labels,r'D:\\Training_Data_Creation\\Results_Scatter\\RFreg\\Feature_imp_Test_RF_REG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23fd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
