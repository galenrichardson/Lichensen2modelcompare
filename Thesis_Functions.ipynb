{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860994ab",
   "metadata": {},
   "source": [
    "Citation: Richardson G, Knudby A, Chen W, Sawada M, Lovitt J, He L, et al. (2023) Dense neural network outperforms other machine learning models for scaling-up lichen cover maps in Eastern Canada. PLoS ONE 18(11): e0292839. https://doi.org/10.1371/journal.pone.0292839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7495971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, time, csv,math,scipy,joblib,matplotlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import pearsonr,gaussian_kde\n",
    "from sklearn.inspection import permutation_importance\n",
    "#displaying data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow,figure\n",
    "#TF imports\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536f71a",
   "metadata": {},
   "source": [
    "### Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e467038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are general metrics functions\n",
    "def dtime():\n",
    "    return (datetime.now().strftime(\"%m%d%Y_%H%M%S\"))\n",
    "def calculate_metrics(results):\n",
    "    '''Calculated MAE,r2,pearsons from a results pd.dataframe'''\n",
    "    MAElist= []      #make a list of absolute errors\n",
    "    for i in range(len(results)):\n",
    "        MAElist.append((abs(results[0][i]*100-results[\"pred\"][i]*100)))\n",
    "    mean_MAE=np.round(np.mean(MAElist),3) #calculate mean\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(results[0], results['pred'])\n",
    "    r_squared=r_value**2\n",
    "    corr, _ = pearsonr(results[\"pred\"], results[0])\n",
    "    return mean_MAE,round(r_squared,2),round(corr,3)\n",
    "def time_and_metrics(Results):\n",
    "    dt_string=dtime()\n",
    "    mae,r2,person=calculate_metrics(Results)#calculates metrics\n",
    "    return mae,r2,dt_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22bc0cd",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "763a903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions are for plotting data.\n",
    "def make_scatter_from_results(Results,Results_str,modelplotstr,path):\n",
    "    import matplotlib.ticker as mtick\n",
    "    '''Creates pretty scatterplot and saves it in a meaningful way.\n",
    "    This plot should be used for all Lichen % comparisons between true\n",
    "    and predicted.''' \n",
    "    '''Consider removing empty space on right of figure'''\n",
    "    mae,r2,dt_string=time_and_metrics(Results)\n",
    "    output_path=path+'\\\\'+modelplotstr\n",
    "    image_path='{}\\\\{}_{}-{}_{}.png'.format(output_path,Results_str,mae,r2,dt_string)\n",
    "    if Path(output_path).exists()==False:\n",
    "        os.makedirs(output_path)\n",
    "    x,y=Results[0],Results[\"pred\"]\n",
    "    #work on frequency colouring\n",
    "    xy = np.vstack([x,y])\n",
    "    z = gaussian_kde(xy)(xy/2) \n",
    "    fig = plt.figure(figsize=(7.75,7))#define plot size, 7,6 makes SP a square\n",
    "    #seperate space for plot and Cbar\n",
    "    gs=matplotlib.gridspec.GridSpec(1,2, width_ratios=[6,.2])\n",
    "    ax1 = plt.subplot(gs[0])\n",
    "    plt.xlabel(\"True Values\",size=18)\n",
    "    plt.ylabel(\"Predicted\",size=18)\n",
    "    plt.xticks(np.arange(0,1,step=.1),fontsize=14)\n",
    "    plt.yticks(np.arange(0,1,step=.1),fontsize=14)\n",
    "    plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "    plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "    #plot scatter, 1:1 line\n",
    "    sc=ax1.scatter(x, y, c=z,cmap='viridis')\n",
    "    #used to create 1:1 line\n",
    "    line=ax1.plot(Results[0], Results[0], color = 'black', label = '1:1 Line',alpha=0.6)\n",
    "    #used to create regression line\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(Results[0], Results['pred'])\n",
    "    x_vals = np.array((0,ax1.get_xlim()[1]))\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    reg=ax1.plot(x_vals,y_vals,color = 'red',label = 'Linear Regression',alpha=0.6)\n",
    "    #add # samples to items as smalle r\n",
    "    ax1.legend(loc='upper left',fontsize=16,frameon=False)\n",
    "    #Title of plot\n",
    "    ax1.set_title('MAE = {}         R\\u00b2 = {}         n = {}'.format(np.round(mae*.01,4)\n",
    "                                                                          ,r2,str(len(Results[0]))),fontsize=18,pad=10)\n",
    "    cbar=plt.colorbar(sc, cax=ax2)\n",
    "    cbar.remove() \n",
    "    #plt.tight_layout()\n",
    "    plt.savefig(image_path,dpi=500) #save image\n",
    "\n",
    "def plot_hist_save(model,temp_weights,val_dataset,model_history,path,NN_str):\n",
    "    '''Saves the model history in a meaningful way. This function should\n",
    "    be used for every NN model which is tested, and for Hyperparam tuning.'''\n",
    "    mae=get_model_mae(model,temp_weights,val_dataset)\n",
    "    dt_string = dtime()\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    plt.xlabel('Epoch',size=10)\n",
    "    plt.ylabel('MAE Loss',size=10)\n",
    "    plt.title('Model Loss per Epoch',size=12)\n",
    "    plt.plot(model_history.history['loss'],'cornflowerblue')\n",
    "    plt.plot(model_history.history['val_loss'],'darkred')\n",
    "    plt.legend(['Training Loss','Validation Loss'],loc='upper right',fontsize=9,frameon=True)\n",
    "    plt.grid()\n",
    "    plt.savefig('{}\\{}\\Histplot-{}_{}.png'.format(path,NN_str,str(round(mae,5)),dt_string),dpi=400)#save image\n",
    "def Feature_importance(rf_reg,test,test_labels,imgpath):\n",
    "    result = permutation_importance(\n",
    "        rf_reg, test, test_labels, n_repeats=10, random_state=42, n_jobs=2)\n",
    "\n",
    "    forest_importances = pd.Series(result.importances_mean)\n",
    "    x=[\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B11\",\"B12\"]\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(ax=ax, color='black')\n",
    "    ax.set_title(\"Feature importances using permutation on RF model\",fontsize=12)\n",
    "    ax.set_xticks(range(9),labels=x,rotation=0)\n",
    "    ax.set_ylabel(\"Mean accuracy decrease\",fontsize=12),ax.set_xlabel(\"Sentinel-2 Bands\",fontsize=12)\n",
    "    #fig.tight_layout()\n",
    "    plt.savefig(imgpath,dpi=400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb53b6",
   "metadata": {},
   "source": [
    "### NN Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab0e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions are made for Dense NN's\n",
    "def get_model_mae(model,temp_weights,val_dataset):\n",
    "    model.load_weights(temp_weights)\n",
    "    _,mae,_ = model.evaluate(val_dataset)\n",
    "    return mae\n",
    "def save_nn_for_log(model,temp_weights,val_dataset,path,NN_str):\n",
    "    '''saves the model weights in a meaningful way'''\n",
    "    dt_string = dtime()\n",
    "    mae=get_model_mae(model,temp_weights,val_dataset)\n",
    "    if Path('{}\\{}'.format(path,NN_str)).exists()==False:\n",
    "        os.makedirs('{}\\{}'.format(path,NN_str))\n",
    "    savepath=r'{}\\{}\\Weights-{}_{}.h5'.format(path,NN_str,str(round(mae,5)),dt_string)\n",
    "    model.save(savepath)\n",
    "    print('Weights saved')\n",
    "def nnDset_to_Results(model,nnDataset):\n",
    "    '''evaluates TF dataset and creates Results pd.dataframe'''\n",
    "    results_list=[]\n",
    "    for element in nnDataset.as_numpy_iterator(): \n",
    "        result=model.predict(element[0])\n",
    "        results_list.append([element[1]*100,result*100])\n",
    "    x,y=[],[]\n",
    "    for i in results_list[0][0]:\n",
    "        x.append(abs(i)/100)\n",
    "    for i in results_list[0][1]:\n",
    "        y.append(abs(i[0])/100)\n",
    "    results_nn=pd.DataFrame(list(zip(x,y)),columns = [0,'pred'])\n",
    "    return results_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d2b2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
